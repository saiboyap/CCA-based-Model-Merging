{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i2FyChsNS6D",
        "outputId": "c5b697af-ea15-4bbb-f12b-ba4526ea1608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training Model A...\n",
            "Epoch [1/5], Loss: 1.2748\n",
            "Epoch [2/5], Loss: 0.8913\n",
            "Epoch [3/5], Loss: 0.7051\n",
            "Epoch [4/5], Loss: 0.5386\n",
            "Epoch [5/5], Loss: 0.3801\n",
            "Finished Training\n",
            "Training Model B...\n",
            "Epoch [1/5], Loss: 1.2941\n",
            "Epoch [2/5], Loss: 0.9054\n",
            "Epoch [3/5], Loss: 0.7280\n",
            "Epoch [4/5], Loss: 0.5704\n",
            "Epoch [5/5], Loss: 0.4269\n",
            "Finished Training\n",
            "Loading Model A...\n",
            "Loading Model B...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-c992b7a90977>:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_A.load_state_dict(torch.load('model_A.pth'))\n",
            "<ipython-input-2-c992b7a90977>:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_B.load_state_dict(torch.load('model_B.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model A Accuracy: 73.84%\n",
            "Model B Accuracy: 73.37%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# Define a simple CNN model (this can be replaced with a more complex model like ResNet, VGG, etc.)\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Train the model\n",
        "def train_model(model, train_loader, epochs=5, learning_rate=0.001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "    print('Finished Training')\n",
        "    return model\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize models\n",
        "model_A = SimpleCNN()\n",
        "model_B = SimpleCNN()\n",
        "\n",
        "# Check if pre-trained models exist\n",
        "if not os.path.exists('model_A.pth'):\n",
        "    print(\"Training Model A...\")\n",
        "    model_A = train_model(model_A, train_loader)\n",
        "    torch.save(model_A.state_dict(), 'model_A.pth')  # Save the model\n",
        "\n",
        "if not os.path.exists('model_B.pth'):\n",
        "    print(\"Training Model B...\")\n",
        "    model_B = train_model(model_B, train_loader)\n",
        "    torch.save(model_B.state_dict(), 'model_B.pth')  # Save the model\n",
        "\n",
        "# Load pre-trained models if they exist\n",
        "if os.path.exists('model_A.pth'):\n",
        "    print(\"Loading Model A...\")\n",
        "    model_A.load_state_dict(torch.load('model_A.pth'))\n",
        "\n",
        "if os.path.exists('model_B.pth'):\n",
        "    print(\"Loading Model B...\")\n",
        "    model_B.load_state_dict(torch.load('model_B.pth'))\n",
        "\n",
        "# Set models to evaluation mode\n",
        "model_A.eval()\n",
        "model_B.eval()\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Test the models after loading or training\n",
        "accuracy_A = evaluate_model(model_A, test_loader)\n",
        "accuracy_B = evaluate_model(model_B, test_loader)\n",
        "\n",
        "print(f'Model A Accuracy: {accuracy_A:.2f}%')\n",
        "print(f'Model B Accuracy: {accuracy_B:.2f}%')\n",
        "\n",
        "# You can further extend the code here to perform the model merging techniques\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def base_models_avg(models, test_loader):\n",
        "    accuracies = []\n",
        "    for model in models:\n",
        "        acc = evaluate_model(model, test_loader)\n",
        "        accuracies.append(acc)\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    print(f\"Base Models Avg Accuracy: {avg_accuracy:.2f}%\")\n",
        "    return avg_accuracy\n",
        "\n",
        "# Evaluate Base Models Avg\n",
        "models = [model_A, model_B]  # You can add more models if available\n",
        "base_avg_accuracy = base_models_avg(models, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPa4h7J7Qcnm",
        "outputId": "52f4b90f-a1fc-4e8f-d516-f894df6f17fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base Models Avg Accuracy: 73.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble_models(models, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = [model(images) for model in models]\n",
        "            ensemble_output = torch.mean(torch.stack(outputs), dim=0)  # Averaging logits\n",
        "            _, predicted = torch.max(ensemble_output, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Ensemble Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate Ensemble Accuracy\n",
        "ensemble_accuracy = ensemble_models(models, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2_x5friQfoQ",
        "outputId": "58858dd0-62c0-4f2b-ae20-078704417c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Accuracy: 76.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def direct_averaging(models):\n",
        "    # Ensure the same architecture for all models\n",
        "    merged_model = models[0]  # Use model A's architecture as base\n",
        "    with torch.no_grad():\n",
        "        for param_A, *param_others in zip(models[0].parameters(), *[m.parameters() for m in models[1:]]):\n",
        "            # Average all model parameters\n",
        "            averaged_weights = torch.mean(torch.stack([param_A] + param_others), dim=0)\n",
        "            param_A.data.copy_(averaged_weights)\n",
        "    return merged_model\n",
        "\n",
        "# Merge and evaluate Direct Averaging\n",
        "direct_avg_model = direct_averaging([model_A, model_B])\n",
        "direct_avg_accuracy = evaluate_model(direct_avg_model, test_loader)\n",
        "print(f\"Direct Averaging Accuracy: {direct_avg_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0YAyza1Qi5Z",
        "outputId": "5b86d93f-2441-45b8-8b06-e587205322ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Direct Averaging Accuracy: 29.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Function to generate a permutation matrix\n",
        "def get_permutation_matrix(param_A, param_B):\n",
        "    # Ensure only layers with the same number of neurons are permuted\n",
        "    if param_A.size(0) == param_B.size(0):\n",
        "        return torch.randperm(param_A.size(0))\n",
        "    else:\n",
        "        return None  # Skip if the layers are not compatible\n",
        "\n",
        "# Function to apply the permutation\n",
        "def apply_permutation(param_B, permutation):\n",
        "    # Apply permutation based on layer type (fully connected or convolutional)\n",
        "    if permutation is not None:\n",
        "        if param_B.dim() == 2:  # Fully connected layer\n",
        "            return param_B[permutation, :]  # Permuting rows (neurons)\n",
        "        elif param_B.dim() == 1:  # Bias layer\n",
        "            return param_B[permutation]\n",
        "        elif param_B.dim() == 4:  # Convolutional layer\n",
        "            return param_B[permutation, :, :, :]  # Permute filters (output channels)\n",
        "    return param_B  # If no permutation, return param_B unchanged\n",
        "\n",
        "# Main function to permute neurons\n",
        "def permute_neurons(model_A, model_B):\n",
        "    with torch.no_grad():\n",
        "        for param_A, param_B in zip(model_A.parameters(), model_B.parameters()):\n",
        "            if param_A.shape == param_B.shape:  # Ensure layers have the same shape\n",
        "                # Get the permutation matrix for matching neurons\n",
        "                permutation_matrix = get_permutation_matrix(param_A, param_B)\n",
        "                if permutation_matrix is not None:\n",
        "                    permuted_param_B = apply_permutation(param_B, permutation_matrix)\n",
        "                    if param_A.data.shape == permuted_param_B.shape:  # Check if blending is safe\n",
        "                        param_A.data = 0.5 * (param_A.data + permuted_param_B)\n",
        "                    else:\n",
        "                        print(f\"Shape mismatch after permutation: {param_A.shape} vs {permuted_param_B.shape}\")\n",
        "                else:\n",
        "                    print(f\"Skipping incompatible layer due to mismatch: {param_A.shape}\")\n",
        "            else:\n",
        "                print(f\"Skipping incompatible layer with shapes {param_A.shape} and {param_B.shape}\")\n",
        "\n",
        "    return model_A\n",
        "\n",
        "# Assuming model_A and model_B are already defined and initialized somewhere above this code\n",
        "permute_model = permute_neurons(model_A, model_B)\n",
        "permute_accuracy = evaluate_model(permute_model, test_loader)  # Assuming evaluate_model is defined\n",
        "print(f\"Permute Accuracy: {permute_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N46gGIkQl0X",
        "outputId": "b02d9757-878b-401c-fe3d-8277a89cb5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Permute Accuracy: 11.38%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def dummy_optimal_transport_align(model_A, model_B):\n",
        "    # Placeholder function for optimal transport neuron alignment\n",
        "    # We'll simply average the weights of the two models.\n",
        "    aligned_model = model_A  # Start with model_A as the base\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Aligning parameters between model_A and model_B\n",
        "        for param_A, param_B in zip(model_A.parameters(), model_B.parameters()):\n",
        "            param_A.data = (param_A.data + param_B.data) / 2  # Averaging the weights\n",
        "    return aligned_model\n",
        "\n",
        "def ot_fusion(models):\n",
        "    merged_model = models[0]  # Use the first model as the base\n",
        "\n",
        "    # Loop over model parameters and average weights\n",
        "    with torch.no_grad():\n",
        "        for params in zip(*[model.parameters() for model in models]):\n",
        "            # Stack the parameters only if their shapes match\n",
        "            stacked_params = torch.stack([p.data for p in params if p.shape == params[0].shape])\n",
        "            # Average the stacked parameters\n",
        "            params[0].data.copy_(torch.mean(stacked_params, dim=0))\n",
        "\n",
        "    return merged_model\n",
        "\n",
        "# Merge and evaluate OT Fusion\n",
        "ot_model = ot_fusion([model_A, model_B])\n",
        "ot_fusion_accuracy = evaluate_model(ot_model, test_loader)\n",
        "print(f\"OT Fusion Accuracy: {ot_fusion_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCPll4lXQq26",
        "outputId": "dbc387e6-d5b8-4740-ee4a-091d86ab3280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OT Fusion Accuracy: 72.81%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def matching_weights(models):\n",
        "    merged_model = models[0]  # Use model A as base\n",
        "    with torch.no_grad():\n",
        "        for param_A, param_B in zip(models[0].parameters(), models[1].parameters()):\n",
        "            # Directly match weights by averaging\n",
        "            param_A.data = 0.5 * (param_A.data + param_B.data)\n",
        "    return merged_model\n",
        "\n",
        "# Merge and evaluate Matching Weights\n",
        "matching_weights_model = matching_weights([model_A, model_B])\n",
        "matching_weights_accuracy = evaluate_model(matching_weights_model, test_loader)\n",
        "print(f\"Matching Weights Accuracy: {matching_weights_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmom0vFsQtmK",
        "outputId": "39a42583-4475-41e5-8b5d-f6822a4d285c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matching Weights Accuracy: 73.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def zipit_merge_function(models):\n",
        "    # Placeholder function for ZipIt-like model merging\n",
        "    # We'll simply average the weights of the models here.\n",
        "    merged_model = models[0]  # Start with model_A as the base\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Averaging parameters between models\n",
        "        for params in zip(*[model.parameters() for model in models]):\n",
        "            # Ensure that all parameters have the same shape before merging\n",
        "            stacked_params = torch.stack([p.data for p in params if p.shape == params[0].shape])\n",
        "            # Take the mean of stacked parameters\n",
        "            params[0].data.copy_(torch.mean(stacked_params, dim=0))\n",
        "\n",
        "    return merged_model\n",
        "\n",
        "def zipit_merge(models):\n",
        "    merged_model = zipit_merge_function(models)\n",
        "    return merged_model\n",
        "\n",
        "# Merge and evaluate ZipIt!\n",
        "zipit_model = zipit_merge([model_A, model_B])\n",
        "zipit_accuracy = evaluate_model(zipit_model, test_loader)\n",
        "print(f\"ZipIt! Accuracy: {zipit_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R43gfYEnQwTm",
        "outputId": "1d209cd8-920c-4b01-ff51-ff4f7478822c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZipIt! Accuracy: 73.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def cca_merge(models):\n",
        "    # Placeholder CCA merge function: Averaging model parameters for now.\n",
        "    merged_model = models[0]  # Start with model_A as the base\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Average the parameters between the models\n",
        "        for params in zip(*[model.parameters() for model in models]):\n",
        "            # Ensure parameters have the same shape before merging\n",
        "            stacked_params = torch.stack([p.data for p in params if p.shape == params[0].shape])\n",
        "            # Take the mean of stacked parameters\n",
        "            params[0].data.copy_(torch.mean(stacked_params, dim=0))\n",
        "\n",
        "    return merged_model\n",
        "\n",
        "# Merge and evaluate CCA Merge\n",
        "cca_merged_model = cca_merge([model_A, model_B])\n",
        "cca_merge_accuracy = evaluate_model(cca_merged_model, test_loader)\n",
        "print(f\"CCA Merge Accuracy: {cca_merge_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdf-IyL3Qzpp",
        "outputId": "70885f26-3691-4d9f-9b67-c7ac9b739650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CCA Merge Accuracy: 73.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame({\n",
        "    \"Method\": [\"Base Models Avg\", \"Ensemble\", \"Direct Averaging\", \"Permute\", \"OT Fusion\", \"Matching Weights\", \"ZipIt!\", \"CCA Merge\"],\n",
        "    \"Accuracy (%)\": [base_avg_accuracy, ensemble_accuracy, direct_avg_accuracy, permute_accuracy, ot_fusion_accuracy, matching_weights_accuracy, zipit_accuracy, cca_merge_accuracy]\n",
        "})\n",
        "\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx-DSRukQ0jv",
        "outputId": "93bcca94-72d2-46b5-8777-fde6fa9c0648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Method  Accuracy (%)\n",
            "0   Base Models Avg        73.605\n",
            "1          Ensemble        76.270\n",
            "2  Direct Averaging        29.570\n",
            "3           Permute        11.380\n",
            "4         OT Fusion        72.810\n",
            "5  Matching Weights        73.120\n",
            "6            ZipIt!        73.290\n",
            "7         CCA Merge        73.400\n"
          ]
        }
      ]
    }
  ]
}